{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier for Hard Negative Mining Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "import time \n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# This is to make matplotlib figures appear inline in the notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# So the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing train set\n",
      "Done processing dev set\n",
      "Done processing test set\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'facesDataAll'\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'dev': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "    transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'dev', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=1,\n",
    "                                              shuffle=True, num_workers=0)\n",
    "               for x in ['train', 'dev', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'dev', 'test']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Iterate over data.\n",
    "X_train = []\n",
    "y_train = []\n",
    "for data in dataloaders['train']:\n",
    "    # get the inputs\n",
    "    image, label = data\n",
    "    #image, label = Variable(input), Variable(label)\n",
    "\n",
    "    # save all histogram of gradients to file so SVM can run on it\n",
    "\n",
    "    #path = \"./Data/dev/attractive/3e9004df7724847e81162dace6922a6d.jpg\"\n",
    "    #image = cv2.imread(path, 0)\n",
    "    newImage = image.numpy()[0, 0, :, :]\n",
    "\n",
    "    X_train.append(image.numpy())\n",
    "    y_train.append(label)\n",
    "print('Done processing train set')\n",
    "\n",
    "\n",
    "X_dev = []\n",
    "y_dev = []\n",
    "for data in dataloaders['dev']:\n",
    "    # get the inputs\n",
    "    image, label = data\n",
    "\n",
    "    # save all histogram of gradients to file so SVM can run on it\n",
    "\n",
    "#     newImage = image.numpy()[0, 0, :, :]\n",
    "\n",
    "    X_dev.append(image.numpy())\n",
    "    y_dev.append(label)\n",
    "print('Done processing dev set')\n",
    "\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for data in dataloaders['test']:\n",
    "    # get the inputs\n",
    "    image, label = data\n",
    "\n",
    "    # save all histogram of gradients to file so SVM can run on it\n",
    "\n",
    "    newImage = image.numpy()[0, 0, :, :]\n",
    "\n",
    "    X_test.append(image.numpy())\n",
    "    y_test.append(label)\n",
    "print('Done processing test set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_dev = np.array(X_dev)\n",
    "y_dev = np.array(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (948, 150528)\n",
      "Train labels shape:  (948, 1)\n",
      "Test data shape:  (183, 150528)\n",
      "Test labels shape:  (183, 1)\n",
      "Dev data shape:  (180, 150528)\n",
      "Dev labels shape:  (180, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Flatten and convert data into rows as part of out preprocess\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "\n",
    "#reshape y's\n",
    "y_train = np.reshape(y_train, (X_train.shape[0], 1))\n",
    "y_test = np.reshape(y_test, (X_test.shape[0], 1))\n",
    "y_dev = np.reshape(y_dev, (X_dev.shape[0], 1))\n",
    "\n",
    "#Sanity Check\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "\n",
    "print('Dev data shape: ', X_dev.shape)\n",
    "print('Dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "\n",
    "X_train -= mean_image\n",
    "# X_val -= mean_image\n",
    "X_test -= mean_image\n",
    "X_dev -= mean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(948, 150529) (183, 150529) (180, 150529)\n"
     ]
    }
   ],
   "source": [
    "# Add bias\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "# X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "\n",
    "# print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)\n",
    "print(X_train.shape, X_test.shape, X_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "Ready to compute SGD to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]That took 163.541493s\n",
      "Train acc:  0.918776371308\n",
      "Test acc:  0.573770491803\n"
     ]
    }
   ],
   "source": [
    "# from utils.classifiers import LinearSVM\n",
    "# svm = LinearSVM()\n",
    "# tic = time.time()\n",
    "# loss_hist = svm.train(X_train, y_train, learning_rate=1e-7, reg=2.5e4,\n",
    "#                       num_iters=1500, verbose=True)\n",
    "# toc = time.time()\n",
    "# print('That took %fs' % (toc - tic))\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(verbose=True)\n",
    "tic = time.time()\n",
    "clf.fit(X_train, y_train.ravel()) \n",
    "toc = time.time()\n",
    "print('That took %fs' % (toc - tic))\n",
    "\n",
    "\n",
    "test_acc = clf.score(X_test, y_test.ravel())\n",
    "train_acc = clf.score(X_train, y_train.ravel())\n",
    "print('Train acc: ', train_acc)\n",
    "print('Test acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc linear:  1.0\n",
      "Test acc linear:  0.464480874317\n"
     ]
    }
   ],
   "source": [
    "clfLin = SVC(kernel='linear')\n",
    "tic = time.time()\n",
    "clfLin.fit(X_train, y_train.ravel()) \n",
    "toc = time.time()\n",
    "print('That took %fs' % (toc - tic))\n",
    "\n",
    "test_accLin = clfLin.score(X_test, y_test.ravel())\n",
    "train_accLin = clfLin.score(X_train, y_train.ravel())\n",
    "print('Train acc linear: ', train_accLin)\n",
    "print('Test acc linear: ', test_accLin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
